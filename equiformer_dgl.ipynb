{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "Q = torch.tensor([[ 0.3367,  0.1288],\n",
    "        [ 0.2345,  0.2303],\n",
    "        [-1.1229, -0.1863]])\n",
    "K = torch.tensor([[ 2.2082, -0.6380],\n",
    "        [ 0.4617,  0.2674],\n",
    "        [ 0.5349,  0.8094]])\n",
    "V = torch.tensor([[ 1.1103, -1.6898],\n",
    "        [-0.9890,  0.9580],\n",
    "        [ 1.3221,  0.8172]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_k = d_q\n",
    "# d_v\n",
    "d_k = K.shape[1]\n",
    "attention = torch.softmax((Q@K.T)/math.sqrt(d_k),-1)\n",
    "values = attention @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4028, 0.2886, 0.3086],\n",
       "         [0.3538, 0.3069, 0.3393],\n",
       "         [0.1303, 0.4630, 0.4067]]),\n",
       " tensor([[ 0.5697, -0.1520],\n",
       "         [ 0.5379, -0.0265],\n",
       "         [ 0.2246,  0.5556]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from dgl.nn import GraphConv, GATv2Conv\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphConvDGL(g, node_feats):\n",
    "    g=g.add_self_loop()\n",
    "    conv = GraphConv(2, 2, norm='right', weight=False, bias=False)\n",
    "    print(conv)\n",
    "    return conv(g, node_feats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
    "                            [1, 1, 1, 1],\n",
    "                            [0, 1, 1, 1],\n",
    "                            [0, 1, 1, 1]]])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src, dest = torch.nonzero(adj_matrix[0], as_tuple=True)\n",
    "g = dgl.graph((src,dest))\n",
    "nx.draw(g.add_self_loop().to_networkx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1.],\n",
       "         [2., 3.],\n",
       "         [4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphConv(in=2, out=2, normalization=right, activation=None)\n",
      "torch.Size([4, 2])\n",
      "GraphConv(in=2, out=2, normalization=right, activation=None)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(GraphConvDGL(g, node_feats[0]).shape)\n",
    "    GraphConvDGL(g, node_feats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            node_feats (_type_): batch_size, n, m\n",
    "            adj_matrix (_type_): n*n\n",
    "        \"\"\"\n",
    "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "        node_feats = node_feats / num_neighbours\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GCNLayer(c_in=2, c_out=2)\n",
    "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
    "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8789, -0.1742]],\n",
       "\n",
       "        [[ 1.9356,  3.1529]],\n",
       "\n",
       "        [[ 1.9467,  3.1879]],\n",
       "\n",
       "        [[ 1.9450,  3.1826]]], grad_fn=<GSpMMBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatv2conv = GATv2Conv(2, 2, num_heads=1)\n",
    "gatv2conv(g, node_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "dataset = CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "num_class = dataset.num_classes\n",
    "# get node feature\n",
    "feat = g.ndata['feat']\n",
    "# get data split\n",
    "train_mask = g.ndata['train_mask']\n",
    "val_mask = g.ndata['val_mask']\n",
    "test_mask = g.ndata['test_mask']\n",
    "# get labels\n",
    "label = g.ndata['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = dgl.dataloading.GraphDataLoader(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0063, -0.0149, -0.0016,  ...,  0.0066,  0.0092,  0.0043],\n",
       "         [ 0.0024, -0.0098, -0.0046,  ..., -0.0158,  0.0100,  0.0082]],\n",
       "\n",
       "        [[ 0.0004,  0.0058,  0.0003,  ...,  0.0043, -0.0078, -0.0120],\n",
       "         [-0.0112, -0.0040,  0.0016,  ..., -0.0069,  0.0037,  0.0104]],\n",
       "\n",
       "        [[-0.0078, -0.0075, -0.0041,  ...,  0.0083, -0.0018, -0.0009],\n",
       "         [ 0.0104, -0.0195, -0.0051,  ..., -0.0075, -0.0045,  0.0140]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0024,  0.0129,  0.0098,  ...,  0.0175,  0.0121,  0.0079],\n",
       "         [-0.0016, -0.0126,  0.0118,  ..., -0.0103, -0.0466, -0.0162]],\n",
       "\n",
       "        [[-0.0025,  0.0002, -0.0012,  ...,  0.0068, -0.0068,  0.0012],\n",
       "         [-0.0001, -0.0088,  0.0041,  ...,  0.0005, -0.0063,  0.0051]],\n",
       "\n",
       "        [[-0.0059, -0.0038, -0.0021,  ...,  0.0125, -0.0053,  0.0067],\n",
       "         [ 0.0015, -0.0077,  0.0028,  ..., -0.0004, -0.0023,  0.0135]]],\n",
       "       grad_fn=<GSpMMBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_layer = GATv2Conv(g.ndata['feat'].shape[1], g.ndata['label'].unique().shape[0], num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 2, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_layer(g, g.ndata['feat']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n",
    "\n",
    "    def __init__(self, channels_in, channels_hidden, channels_out, num_heads, num_layers=2, dp_rate=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        c_in = channels_in\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(GATv2Conv(c_in, channels_hidden, num_heads=num_heads, feat_drop=dp_rate))\n",
    "            c_in = channels_hidden*num_heads\n",
    "        layers.append(GATv2Conv(c_in, channels_out, num_heads=num_heads))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "# https://github.com/dmlc/dgl/issues/3448\n",
    "    def forward(self, g, ft):\n",
    "        for layer in self.layers:\n",
    "            print(layer)\n",
    "            ft = layer(g, ft)\n",
    "            print(ft.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATv2Conv(\n",
      "  (fc_src): Linear(in_features=1433, out_features=32, bias=True)\n",
      "  (fc_dst): Linear(in_features=1433, out_features=32, bias=True)\n",
      "  (feat_drop): Dropout(p=0.1, inplace=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      ")\n",
      "torch.Size([2708, 2, 16])\n",
      "GATv2Conv(\n",
      "  (fc_src): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (fc_dst): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (feat_drop): Dropout(p=0.1, inplace=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5416x16 and 32x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m gat \u001b[39m=\u001b[39m GATModel(channels_in\u001b[39m=\u001b[39mg\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m      2\u001b[0m                channels_out\u001b[39m=\u001b[39mg\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m                channels_hidden\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, num_heads\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m gat(g, g\u001b[39m.\u001b[39;49mndata[\u001b[39m'\u001b[39;49m\u001b[39mfeat\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/code/oc_play/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m, in \u001b[0;36mGATModel.forward\u001b[0;34m(self, g, ft)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(layer)\n\u001b[0;32m---> 16\u001b[0m     ft \u001b[39m=\u001b[39m layer(g, ft)\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(ft\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/code/oc_play/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/oc_play/venv/lib/python3.9/site-packages/dgl/nn/pytorch/conv/gatv2conv.py:291\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, graph, feat, get_attention)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     h_src \u001b[39m=\u001b[39m h_dst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeat_drop(feat)\n\u001b[0;32m--> 291\u001b[0m     feat_src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_src(h_src)\u001b[39m.\u001b[39mview(\n\u001b[1;32m    292\u001b[0m         \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_feats\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_weights:\n\u001b[1;32m    295\u001b[0m         feat_dst \u001b[39m=\u001b[39m feat_src\n",
      "File \u001b[0;32m~/code/oc_play/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/oc_play/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5416x16 and 32x32)"
     ]
    }
   ],
   "source": [
    "gat = GATModel(channels_in=g.ndata['feat'].shape[1],\n",
    "               channels_out=g.ndata['label'].unique().shape[0],\n",
    "               channels_hidden=16, num_heads=2)\n",
    "gat(g, g.ndata['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassificationPL(pl.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = GATModel()\n",
    "\n",
    "    def forward(self, node_ft, edge):\n",
    "        note_ft = data[]\n",
    "        self.model(node_ft, edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Epoch 0 | Loss 1.9464285373687744\n",
      "Epoch 1 | Loss 1.930116891860962\n",
      "Epoch 2 | Loss 1.9133331775665283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaum/code/oc_play/venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/chaum/code/oc_play/venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss 1.8966186046600342\n",
      "Epoch 4 | Loss 1.8795205354690552\n",
      "Epoch 5 | Loss 1.8617174625396729\n",
      "Epoch 6 | Loss 1.8431038856506348\n",
      "Epoch 7 | Loss 1.8235259056091309\n",
      "Epoch 8 | Loss 1.802789330482483\n",
      "Epoch 9 | Loss 1.7807276248931885\n",
      "Epoch 10 | Loss 1.7572115659713745\n",
      "Epoch 11 | Loss 1.7321330308914185\n",
      "Epoch 12 | Loss 1.7054029703140259\n",
      "Epoch 13 | Loss 1.6769614219665527\n",
      "Epoch 14 | Loss 1.6467628479003906\n",
      "Epoch 15 | Loss 1.6147487163543701\n",
      "Epoch 16 | Loss 1.5808830261230469\n",
      "Epoch 17 | Loss 1.5451945066452026\n",
      "Epoch 18 | Loss 1.5077282190322876\n",
      "Epoch 19 | Loss 1.468510389328003\n",
      "Epoch 20 | Loss 1.4275953769683838\n",
      "Epoch 21 | Loss 1.385091781616211\n",
      "Epoch 22 | Loss 1.3411457538604736\n",
      "Epoch 23 | Loss 1.2958875894546509\n",
      "Epoch 24 | Loss 1.2494970560073853\n",
      "Epoch 25 | Loss 1.202166199684143\n",
      "Epoch 26 | Loss 1.1541026830673218\n",
      "Epoch 27 | Loss 1.1055423021316528\n",
      "Epoch 28 | Loss 1.056715726852417\n",
      "Epoch 29 | Loss 1.0078448057174683\n",
      "Epoch 30 | Loss 0.9591891765594482\n",
      "Epoch 31 | Loss 0.9109888672828674\n",
      "Epoch 32 | Loss 0.8634492754936218\n",
      "Epoch 33 | Loss 0.816789984703064\n",
      "Epoch 34 | Loss 0.7711997032165527\n",
      "Epoch 35 | Loss 0.7268543243408203\n",
      "Epoch 36 | Loss 0.6838908791542053\n",
      "Epoch 37 | Loss 0.6424697637557983\n",
      "Epoch 38 | Loss 0.6026760339736938\n",
      "Epoch 39 | Loss 0.5646207928657532\n",
      "Epoch 40 | Loss 0.5283704400062561\n",
      "Epoch 41 | Loss 0.49395811557769775\n",
      "Epoch 42 | Loss 0.4614168405532837\n",
      "Epoch 43 | Loss 0.4307470917701721\n",
      "Epoch 44 | Loss 0.4019339680671692\n",
      "Epoch 45 | Loss 0.37495025992393494\n",
      "Epoch 46 | Loss 0.34974604845046997\n",
      "Epoch 47 | Loss 0.32625359296798706\n",
      "Epoch 48 | Loss 0.3044007420539856\n",
      "Epoch 49 | Loss 0.28411635756492615\n",
      "Epoch 50 | Loss 0.26530522108078003\n",
      "Epoch 51 | Loss 0.24789245426654816\n",
      "Epoch 52 | Loss 0.23180237412452698\n",
      "Epoch 53 | Loss 0.2169753462076187\n",
      "Epoch 54 | Loss 0.2032797932624817\n",
      "Epoch 55 | Loss 0.19063352048397064\n",
      "Epoch 56 | Loss 0.17896153032779694\n",
      "Epoch 57 | Loss 0.16819314658641815\n",
      "Epoch 58 | Loss 0.1582038700580597\n",
      "Epoch 59 | Loss 0.1489870250225067\n",
      "Epoch 60 | Loss 0.1404709666967392\n",
      "Epoch 61 | Loss 0.13261781632900238\n",
      "Epoch 62 | Loss 0.125372052192688\n",
      "Epoch 63 | Loss 0.11870467662811279\n",
      "Epoch 64 | Loss 0.11256331950426102\n",
      "Epoch 65 | Loss 0.10690706223249435\n",
      "Epoch 66 | Loss 0.10169519484043121\n",
      "Epoch 67 | Loss 0.09689034521579742\n",
      "Epoch 68 | Loss 0.09245756268501282\n",
      "Epoch 69 | Loss 0.08836349844932556\n",
      "Epoch 70 | Loss 0.0845833271741867\n",
      "Epoch 71 | Loss 0.08109021186828613\n",
      "Epoch 72 | Loss 0.07787029445171356\n",
      "Epoch 73 | Loss 0.07490386068820953\n",
      "Epoch 74 | Loss 0.07216258347034454\n",
      "Epoch 75 | Loss 0.06963209807872772\n",
      "Epoch 76 | Loss 0.06729892641305923\n",
      "Epoch 77 | Loss 0.06515184789896011\n",
      "Epoch 78 | Loss 0.06317295879125595\n",
      "Epoch 79 | Loss 0.06134497746825218\n",
      "Epoch 80 | Loss 0.059667766094207764\n",
      "Epoch 81 | Loss 0.05812140926718712\n",
      "Epoch 82 | Loss 0.05668894574046135\n",
      "Epoch 83 | Loss 0.05536891892552376\n",
      "Epoch 84 | Loss 0.05415423959493637\n",
      "Epoch 85 | Loss 0.05303749814629555\n",
      "Epoch 86 | Loss 0.05200895667076111\n",
      "Epoch 87 | Loss 0.05106234923005104\n",
      "Epoch 88 | Loss 0.05018012598156929\n",
      "Epoch 89 | Loss 0.04937845095992088\n",
      "Epoch 90 | Loss 0.048622895032167435\n",
      "Epoch 91 | Loss 0.04791361466050148\n",
      "Epoch 92 | Loss 0.047260917723178864\n",
      "Epoch 93 | Loss 0.04666326940059662\n",
      "Epoch 94 | Loss 0.046095430850982666\n",
      "Epoch 95 | Loss 0.04556971788406372\n",
      "Epoch 96 | Loss 0.04509103670716286\n",
      "Epoch 97 | Loss 0.0446401908993721\n",
      "Epoch 98 | Loss 0.04421469569206238\n",
      "Epoch 99 | Loss 0.04382099583745003\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import dgl\n",
    "from dgl.nn import GATConv\n",
    "\n",
    "use_fp16 = True\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 heads):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(GATConv(in_feats, n_hidden, heads[0], activation=F.elu))\n",
    "        self.layers.append(GATConv(n_hidden * heads[0], n_hidden, heads[1], activation=F.elu))\n",
    "        self.layers.append(GATConv(n_hidden * heads[1], n_classes, heads[2], activation=F.elu))\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            h = layer(g, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = h.flatten(1)\n",
    "            else:\n",
    "                h = h.mean(1)\n",
    "        return h\n",
    "\n",
    "# Data loading\n",
    "data = CoraGraphDataset()\n",
    "device = \"cpu\"\n",
    "g = data[0]\n",
    "g = dgl.add_self_loop(g)\n",
    "g = g.int().to(device)\n",
    "train_mask = g.ndata['train_mask']\n",
    "features = g.ndata['feat']\n",
    "labels = g.ndata['label']\n",
    "in_feats = features.shape[1]\n",
    "n_hidden = 256\n",
    "n_classes = data.num_classes\n",
    "n_edges = g.number_of_edges()\n",
    "heads = [1, 1, 1]\n",
    "model = GAT(in_feats, n_hidden, n_classes, heads)\n",
    "model = model.to(device)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "# Create gradient scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Wrap forward pass with autocast\n",
    "    with autocast(enabled=use_fp16):\n",
    "        logits = model(g, features)\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    if use_fp16:\n",
    "        # Backprop w/ gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    else:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch {} | Loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): GATConv(\n",
      "    (fc): Linear(in_features=1433, out_features=256, bias=False)\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (1): GATConv(\n",
      "    (fc): Linear(in_features=256, out_features=256, bias=False)\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (2): GATConv(\n",
      "    (fc): Linear(in_features=256, out_features=7, bias=False)\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
